{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0902141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display, Math\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "import json\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "from utils import *\n",
    "from model_utils import *\n",
    "#from model_VAE import VAE\n",
    "\n",
    "sys_epsilon = sys.float_info.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b665b",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4895d",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149e7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"t\",                                             # time\n",
    "           \"X\", \"Y\", \"Z\",                                   # spacial coordinates\n",
    "           \"Ux\", \"Uy\", \"Uz\",                                # velocity components\n",
    "           \"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\",              # velocity gradient tensor components\n",
    "           \"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\",              # strain rate tensor compnents\n",
    "           \"UUp1\", \"UUp2\", \"UUp3\", \"UUp4\", \"UUp5\", \"UUp6\",  # resolved Reynolds stress tensor components\n",
    "           \"Cs\"]                                            # Smagorinsky coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd48176",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a57c93",
   "metadata": {},
   "source": [
    "#### $\\mathcal Re = 10^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c132f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re = 10^3 seen\n",
    "with open('../processedDatasets/fieldData_R3_seen_means.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R103_seen_means = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "with open('../processedDatasets/fieldData_R3_seen_scales.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R103_seen_scales = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "dSn_R103_seen = pd.read_csv('../processedDatasets/fieldData_R3_seen_norm.txt', sep=' ', names=headers)\n",
    "dS_R103_seen = pd.read_csv('../processedDatasets/fieldData_R3_seen.txt', sep=' ', names=headers)\n",
    "\n",
    "# Re = 10^3 unseen\n",
    "with open('../processedDatasets/fieldData_R3_unseen_means.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R103_unseen_means = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "with open('../processedDatasets/fieldData_R3_unseen_scales.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R103_unseen_scales = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "dSn_R103_unseen = pd.read_csv('../processedDatasets/fieldData_R3_unseen_norm.txt', sep=' ', names=headers)\n",
    "dS_R103_unseen = pd.read_csv('../processedDatasets/fieldData_R3_unseen.txt', sep=' ', names=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16c915",
   "metadata": {},
   "source": [
    "#### $\\mathcal Re = 5\\times 10^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4f6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re = 5 x 10^3 seen\n",
    "with open('../processedDatasets/fieldData_R53_seen_means.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R503_seen_means = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "with open('../processedDatasets/fieldData_R53_seen_scales.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R503_seen_scales = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "dSn_R503_seen = pd.read_csv('../processedDatasets/fieldData_R53_seen_norm.txt', sep=' ', names=headers)\n",
    "dS_R503_seen = pd.read_csv('../processedDatasets/fieldData_R53_seen.txt', sep=' ', names=headers)\n",
    "\n",
    "# Re = 5 x 10^3 unseen\n",
    "with open('../processedDatasets/fieldData_R53_unseen_means.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R503_unseen_means = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "with open('../processedDatasets/fieldData_R53_unseen_scales.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R503_unseen_scales = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "dSn_R503_unseen = pd.read_csv('../processedDatasets/fieldData_R53_unseen_norm.txt', sep=' ', names=headers)\n",
    "dS_R503_unseen = pd.read_csv('../processedDatasets/fieldData_R53_unseen.txt', sep=' ', names=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04baaae2",
   "metadata": {},
   "source": [
    "#### $\\mathcal Re = 10^4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d456184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re = 10^4 seen\n",
    "with open('../processedDatasets/fieldData_R4_seen_means.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R104_seen_means = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "with open('../processedDatasets/fieldData_R4_seen_scales.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R104_seen_scales = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "dSn_R104_seen = pd.read_csv('../processedDatasets/fieldData_R4_seen_norm.txt', sep=' ', names=headers)\n",
    "dS_R104_seen = pd.read_csv('../processedDatasets/fieldData_R4_seen.txt', sep=' ', names=headers)\n",
    "\n",
    "# Re = 10^4 unseen\n",
    "with open('../processedDatasets/fieldData_R4_unseen_means.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R104_unseen_means = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "with open('../processedDatasets/fieldData_R4_unseen_scales.txt', 'r') as file:\n",
    "    data = [float(line.strip()) for line in file]\n",
    "dSn_R104_unseen_scales = pd.DataFrame(np.reshape(data, (-1, len(headers))), columns=headers)\n",
    "\n",
    "dSn_R104_unseen = pd.read_csv('../processedDatasets/fieldData_R4_unseen_norm.txt', sep=' ', names=headers)\n",
    "dS_R104_unseen = pd.read_csv('../processedDatasets/fieldData_R4_unseen.txt', sep=' ', names=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfd467",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73ca0e",
   "metadata": {},
   "source": [
    "# Model Configuration Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c6225",
   "metadata": {},
   "source": [
    "In this section, we consider the different model configurations as presented in the following table.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|l|c|c|c|c|}\n",
    "    \\hline\n",
    "    \\textbf{Model} & \\textbf{Inputs} & \\textbf{No. of Inputs} & \\textbf{Outputs} & \\textbf{No. of Outputs} \\\\\n",
    "    \\hline\n",
    "    \\mathbf{M1} & u_i \\, \\text{and} \\, \\mathcal{S}_{ij} & 9 & c_s & 1\\\\\n",
    "    \\mathbf{M2} & \\mathcal{G}_{ij} \\, \\text{and} \\, \\mathcal{S}_{ij} & 12 & c_s & 1 \\\\\n",
    "    \\mathbf{M3} & u_i \\, \\text{and} \\, \\tau^{'}_{ij} & 9 & c_s & 1 \\\\\n",
    "    \\mathbf{M4} & \\mathcal{G}_{ij} \\, \\text{and} \\, \\tau^{'}_{ij} & 12 & c_s & 1 \\\\\n",
    "    \\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e061aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_headers = ['Ux', 'Uy', 'Uz', 'S1',  'S2', 'S3', 'S4', 'S5', 'S6', 'Cs']\n",
    "M2_headers = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'S1',  'S2', 'S3', 'S4', 'S5', 'S6', 'Cs']\n",
    "M3_headers = ['Ux', 'Uy', 'Uz', 'UUp1',  'UUp2', 'UUp3', 'UUp4', 'UUp5', 'UUp6', 'Cs']\n",
    "M4_headers = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'UUp1',  'UUp2', 'UUp3', 'UUp4', 'UUp5', 'UUp6', 'Cs']\n",
    "\n",
    "M1_103 = dSn_R103_seen.filter(M1_headers, axis=1)\n",
    "M2_103 = dSn_R103_seen.filter(M2_headers, axis=1)\n",
    "M3_103 = dSn_R103_seen.filter(M3_headers, axis=1)\n",
    "M4_103 = dSn_R103_seen.filter(M4_headers, axis=1)\n",
    "\n",
    "M1_503 = dSn_R503_seen.filter(M1_headers, axis=1)\n",
    "M2_503 = dSn_R503_seen.filter(M2_headers, axis=1)\n",
    "M3_503 = dSn_R503_seen.filter(M3_headers, axis=1)\n",
    "M4_503 = dSn_R503_seen.filter(M4_headers, axis=1)\n",
    "\n",
    "M1_104 = dSn_R104_seen.filter(M1_headers, axis=1)\n",
    "M2_104 = dSn_R104_seen.filter(M2_headers, axis=1)\n",
    "M3_104 = dSn_R104_seen.filter(M3_headers, axis=1)\n",
    "M4_104 = dSn_R104_seen.filter(M4_headers, axis=1)\n",
    "\n",
    "M1_103_test = dSn_R103_unseen.filter(M1_headers, axis=1)\n",
    "M2_103_test = dSn_R103_unseen.filter(M2_headers, axis=1)\n",
    "M3_103_test = dSn_R103_unseen.filter(M3_headers, axis=1)\n",
    "M4_103_test = dSn_R103_unseen.filter(M4_headers, axis=1)\n",
    "\n",
    "M1_503_test = dSn_R503_unseen.filter(M1_headers, axis=1)\n",
    "M2_503_test = dSn_R503_unseen.filter(M2_headers, axis=1)\n",
    "M3_503_test = dSn_R503_unseen.filter(M3_headers, axis=1)\n",
    "M4_503_test = dSn_R503_unseen.filter(M4_headers, axis=1)\n",
    "\n",
    "M1_104_test = dSn_R104_unseen.filter(M1_headers, axis=1)\n",
    "M2_104_test = dSn_R104_unseen.filter(M2_headers, axis=1)\n",
    "M3_104_test = dSn_R104_unseen.filter(M3_headers, axis=1)\n",
    "M4_104_test = dSn_R104_unseen.filter(M4_headers, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9cae7",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990fee6",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab2a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = M4_104\n",
    "dt_name = namestr(M4_104, globals())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4cfe154",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sz = 0.8\n",
    "mask = np.random.rand(len(dt)) < split_sz\n",
    "train = dt[mask].reset_index(drop=True) \n",
    "val = dt[~mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23c8f011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>G4</th>\n",
       "      <th>G5</th>\n",
       "      <th>G6</th>\n",
       "      <th>UUp1</th>\n",
       "      <th>UUp2</th>\n",
       "      <th>UUp3</th>\n",
       "      <th>UUp4</th>\n",
       "      <th>UUp5</th>\n",
       "      <th>UUp6</th>\n",
       "      <th>Cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.030288</td>\n",
       "      <td>-0.099401</td>\n",
       "      <td>-0.093050</td>\n",
       "      <td>-0.044349</td>\n",
       "      <td>0.073241</td>\n",
       "      <td>0.071077</td>\n",
       "      <td>-0.621343</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>-0.727846</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>-0.723760</td>\n",
       "      <td>-1.004127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.197695</td>\n",
       "      <td>-0.242680</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>0.835817</td>\n",
       "      <td>-1.329357</td>\n",
       "      <td>0.323531</td>\n",
       "      <td>-0.576310</td>\n",
       "      <td>-0.179442</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>-0.476491</td>\n",
       "      <td>-0.439450</td>\n",
       "      <td>-0.646736</td>\n",
       "      <td>0.517645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030994</td>\n",
       "      <td>0.652822</td>\n",
       "      <td>-0.045647</td>\n",
       "      <td>-0.148220</td>\n",
       "      <td>0.266144</td>\n",
       "      <td>-0.168707</td>\n",
       "      <td>-0.249698</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.543235</td>\n",
       "      <td>-0.440977</td>\n",
       "      <td>-0.039008</td>\n",
       "      <td>-0.175606</td>\n",
       "      <td>-1.158358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.181946</td>\n",
       "      <td>-0.020944</td>\n",
       "      <td>-0.226529</td>\n",
       "      <td>-0.082291</td>\n",
       "      <td>0.444896</td>\n",
       "      <td>0.366172</td>\n",
       "      <td>-0.426727</td>\n",
       "      <td>0.319302</td>\n",
       "      <td>0.126813</td>\n",
       "      <td>-0.350229</td>\n",
       "      <td>0.865285</td>\n",
       "      <td>-0.541787</td>\n",
       "      <td>-0.686264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.671802</td>\n",
       "      <td>-0.761704</td>\n",
       "      <td>0.023589</td>\n",
       "      <td>0.006468</td>\n",
       "      <td>-0.524679</td>\n",
       "      <td>-0.105963</td>\n",
       "      <td>-0.353570</td>\n",
       "      <td>-0.196120</td>\n",
       "      <td>0.414301</td>\n",
       "      <td>-0.421726</td>\n",
       "      <td>-1.029824</td>\n",
       "      <td>-0.323891</td>\n",
       "      <td>0.131864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560013</th>\n",
       "      <td>0.497272</td>\n",
       "      <td>-0.566571</td>\n",
       "      <td>-3.453885</td>\n",
       "      <td>-0.884785</td>\n",
       "      <td>-0.153910</td>\n",
       "      <td>1.150560</td>\n",
       "      <td>2.288330</td>\n",
       "      <td>-2.898927</td>\n",
       "      <td>4.222684</td>\n",
       "      <td>4.088178</td>\n",
       "      <td>0.486467</td>\n",
       "      <td>3.742809</td>\n",
       "      <td>0.653598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560014</th>\n",
       "      <td>0.210802</td>\n",
       "      <td>0.010281</td>\n",
       "      <td>1.138833</td>\n",
       "      <td>0.914302</td>\n",
       "      <td>0.851010</td>\n",
       "      <td>-1.320538</td>\n",
       "      <td>-0.137856</td>\n",
       "      <td>0.121102</td>\n",
       "      <td>-0.623054</td>\n",
       "      <td>-0.325073</td>\n",
       "      <td>-0.726222</td>\n",
       "      <td>-0.028926</td>\n",
       "      <td>0.372382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560015</th>\n",
       "      <td>0.719513</td>\n",
       "      <td>-0.389316</td>\n",
       "      <td>-0.419565</td>\n",
       "      <td>-0.152395</td>\n",
       "      <td>-0.146498</td>\n",
       "      <td>-0.100599</td>\n",
       "      <td>-0.333556</td>\n",
       "      <td>0.240537</td>\n",
       "      <td>-0.080920</td>\n",
       "      <td>-0.096904</td>\n",
       "      <td>-0.444976</td>\n",
       "      <td>-0.156379</td>\n",
       "      <td>-0.127999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560016</th>\n",
       "      <td>0.183035</td>\n",
       "      <td>0.044767</td>\n",
       "      <td>0.739180</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>-0.085614</td>\n",
       "      <td>-0.129985</td>\n",
       "      <td>-0.465270</td>\n",
       "      <td>0.158376</td>\n",
       "      <td>-0.265106</td>\n",
       "      <td>-0.476840</td>\n",
       "      <td>-0.927122</td>\n",
       "      <td>-0.356582</td>\n",
       "      <td>-0.469827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560017</th>\n",
       "      <td>0.185308</td>\n",
       "      <td>-0.076115</td>\n",
       "      <td>0.132383</td>\n",
       "      <td>-0.030572</td>\n",
       "      <td>-0.014254</td>\n",
       "      <td>0.082151</td>\n",
       "      <td>-0.627063</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>-0.741164</td>\n",
       "      <td>-0.106841</td>\n",
       "      <td>-0.738114</td>\n",
       "      <td>-0.177859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560018 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              G1        G2        G3        G4        G5        G6      UUp1  \\\n",
       "0      -0.030288 -0.099401 -0.093050 -0.044349  0.073241  0.071077 -0.621343   \n",
       "1      -0.197695 -0.242680  0.244637  0.835817 -1.329357  0.323531 -0.576310   \n",
       "2      -0.030994  0.652822 -0.045647 -0.148220  0.266144 -0.168707 -0.249698   \n",
       "3      -0.181946 -0.020944 -0.226529 -0.082291  0.444896  0.366172 -0.426727   \n",
       "4      -0.671802 -0.761704  0.023589  0.006468 -0.524679 -0.105963 -0.353570   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "560013  0.497272 -0.566571 -3.453885 -0.884785 -0.153910  1.150560  2.288330   \n",
       "560014  0.210802  0.010281  1.138833  0.914302  0.851010 -1.320538 -0.137856   \n",
       "560015  0.719513 -0.389316 -0.419565 -0.152395 -0.146498 -0.100599 -0.333556   \n",
       "560016  0.183035  0.044767  0.739180  0.015846 -0.085614 -0.129985 -0.465270   \n",
       "560017  0.185308 -0.076115  0.132383 -0.030572 -0.014254  0.082151 -0.627063   \n",
       "\n",
       "            UUp2      UUp3      UUp4      UUp5      UUp6        Cs  \n",
       "0       0.005343  0.001508 -0.727846  0.024628 -0.723760 -1.004127  \n",
       "1      -0.179442  0.034037 -0.476491 -0.439450 -0.646736  0.517645  \n",
       "2      -0.002098 -0.543235 -0.440977 -0.039008 -0.175606 -1.158358  \n",
       "3       0.319302  0.126813 -0.350229  0.865285 -0.541787 -0.686264  \n",
       "4      -0.196120  0.414301 -0.421726 -1.029824 -0.323891  0.131864  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "560013 -2.898927  4.222684  4.088178  0.486467  3.742809  0.653598  \n",
       "560014  0.121102 -0.623054 -0.325073 -0.726222 -0.028926  0.372382  \n",
       "560015  0.240537 -0.080920 -0.096904 -0.444976 -0.156379 -0.127999  \n",
       "560016  0.158376 -0.265106 -0.476840 -0.927122 -0.356582 -0.469827  \n",
       "560017  0.001922  0.000682 -0.741164 -0.106841 -0.738114 -0.177859  \n",
       "\n",
       "[560018 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905ebeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>G4</th>\n",
       "      <th>G5</th>\n",
       "      <th>G6</th>\n",
       "      <th>UUp1</th>\n",
       "      <th>UUp2</th>\n",
       "      <th>UUp3</th>\n",
       "      <th>UUp4</th>\n",
       "      <th>UUp5</th>\n",
       "      <th>UUp6</th>\n",
       "      <th>Cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.229502</td>\n",
       "      <td>-0.082355</td>\n",
       "      <td>-0.049943</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.058222</td>\n",
       "      <td>-0.131098</td>\n",
       "      <td>-0.206289</td>\n",
       "      <td>0.149457</td>\n",
       "      <td>0.584462</td>\n",
       "      <td>-0.410026</td>\n",
       "      <td>0.766261</td>\n",
       "      <td>-0.168835</td>\n",
       "      <td>-0.289756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.618960</td>\n",
       "      <td>-0.582423</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>0.100815</td>\n",
       "      <td>-0.213630</td>\n",
       "      <td>-0.717968</td>\n",
       "      <td>-0.046226</td>\n",
       "      <td>-0.724693</td>\n",
       "      <td>0.063926</td>\n",
       "      <td>-0.055390</td>\n",
       "      <td>-0.104848</td>\n",
       "      <td>-0.493566</td>\n",
       "      <td>0.266733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750543</td>\n",
       "      <td>0.366205</td>\n",
       "      <td>0.141528</td>\n",
       "      <td>-0.943148</td>\n",
       "      <td>-0.561064</td>\n",
       "      <td>0.235249</td>\n",
       "      <td>-0.141035</td>\n",
       "      <td>0.570926</td>\n",
       "      <td>0.142963</td>\n",
       "      <td>0.271379</td>\n",
       "      <td>0.462132</td>\n",
       "      <td>0.058082</td>\n",
       "      <td>-0.044033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.663552</td>\n",
       "      <td>0.894064</td>\n",
       "      <td>0.500579</td>\n",
       "      <td>0.237269</td>\n",
       "      <td>0.854063</td>\n",
       "      <td>0.226380</td>\n",
       "      <td>-0.026175</td>\n",
       "      <td>-0.170825</td>\n",
       "      <td>-0.723355</td>\n",
       "      <td>0.051490</td>\n",
       "      <td>0.990494</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>-0.274570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.098686</td>\n",
       "      <td>-0.093137</td>\n",
       "      <td>0.030419</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.196056</td>\n",
       "      <td>-0.535607</td>\n",
       "      <td>-0.161492</td>\n",
       "      <td>-0.081420</td>\n",
       "      <td>-0.493975</td>\n",
       "      <td>0.608716</td>\n",
       "      <td>-0.589099</td>\n",
       "      <td>-0.503224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139977</th>\n",
       "      <td>-1.148371</td>\n",
       "      <td>-0.213732</td>\n",
       "      <td>1.626341</td>\n",
       "      <td>0.943446</td>\n",
       "      <td>0.194335</td>\n",
       "      <td>0.498926</td>\n",
       "      <td>-0.135747</td>\n",
       "      <td>-0.040028</td>\n",
       "      <td>-0.633390</td>\n",
       "      <td>-0.332281</td>\n",
       "      <td>0.261262</td>\n",
       "      <td>-0.022080</td>\n",
       "      <td>-0.182028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139978</th>\n",
       "      <td>0.874507</td>\n",
       "      <td>0.107767</td>\n",
       "      <td>0.525375</td>\n",
       "      <td>-0.254840</td>\n",
       "      <td>-0.467373</td>\n",
       "      <td>-2.643559</td>\n",
       "      <td>1.235610</td>\n",
       "      <td>-0.862587</td>\n",
       "      <td>3.120241</td>\n",
       "      <td>2.032296</td>\n",
       "      <td>-1.978951</td>\n",
       "      <td>2.847636</td>\n",
       "      <td>0.345989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139979</th>\n",
       "      <td>0.606251</td>\n",
       "      <td>-1.046614</td>\n",
       "      <td>-0.152563</td>\n",
       "      <td>-0.098721</td>\n",
       "      <td>-0.953079</td>\n",
       "      <td>-0.064235</td>\n",
       "      <td>-0.014469</td>\n",
       "      <td>0.883996</td>\n",
       "      <td>0.483994</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>1.341227</td>\n",
       "      <td>-0.175988</td>\n",
       "      <td>0.220853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139980</th>\n",
       "      <td>-0.016059</td>\n",
       "      <td>-0.503635</td>\n",
       "      <td>-0.137585</td>\n",
       "      <td>-0.190025</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.418550</td>\n",
       "      <td>-0.133851</td>\n",
       "      <td>0.294660</td>\n",
       "      <td>0.613317</td>\n",
       "      <td>-0.278234</td>\n",
       "      <td>1.259872</td>\n",
       "      <td>-0.099662</td>\n",
       "      <td>0.093227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139981</th>\n",
       "      <td>-0.325784</td>\n",
       "      <td>-0.157061</td>\n",
       "      <td>-0.205795</td>\n",
       "      <td>-0.114940</td>\n",
       "      <td>0.322107</td>\n",
       "      <td>0.059542</td>\n",
       "      <td>-0.398366</td>\n",
       "      <td>0.130466</td>\n",
       "      <td>-0.347127</td>\n",
       "      <td>-0.497422</td>\n",
       "      <td>-0.857222</td>\n",
       "      <td>-0.358201</td>\n",
       "      <td>0.006298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139982 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              G1        G2        G3        G4        G5        G6      UUp1  \\\n",
       "0      -0.229502 -0.082355 -0.049943  0.005463  0.058222 -0.131098 -0.206289   \n",
       "1      -0.618960 -0.582423 -0.004830  0.100815 -0.213630 -0.717968 -0.046226   \n",
       "2       0.750543  0.366205  0.141528 -0.943148 -0.561064  0.235249 -0.141035   \n",
       "3       0.663552  0.894064  0.500579  0.237269  0.854063  0.226380 -0.026175   \n",
       "4      -0.098686 -0.093137  0.030419  0.007388  0.050987  0.196056 -0.535607   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139977 -1.148371 -0.213732  1.626341  0.943446  0.194335  0.498926 -0.135747   \n",
       "139978  0.874507  0.107767  0.525375 -0.254840 -0.467373 -2.643559  1.235610   \n",
       "139979  0.606251 -1.046614 -0.152563 -0.098721 -0.953079 -0.064235 -0.014469   \n",
       "139980 -0.016059 -0.503635 -0.137585 -0.190025 -0.146906  0.418550 -0.133851   \n",
       "139981 -0.325784 -0.157061 -0.205795 -0.114940  0.322107  0.059542 -0.398366   \n",
       "\n",
       "            UUp2      UUp3      UUp4      UUp5      UUp6        Cs  \n",
       "0       0.149457  0.584462 -0.410026  0.766261 -0.168835 -0.289756  \n",
       "1      -0.724693  0.063926 -0.055390 -0.104848 -0.493566  0.266733  \n",
       "2       0.570926  0.142963  0.271379  0.462132  0.058082 -0.044033  \n",
       "3      -0.170825 -0.723355  0.051490  0.990494  0.350830 -0.274570  \n",
       "4      -0.161492 -0.081420 -0.493975  0.608716 -0.589099 -0.503224  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "139977 -0.040028 -0.633390 -0.332281  0.261262 -0.022080 -0.182028  \n",
       "139978 -0.862587  3.120241  2.032296 -1.978951  2.847636  0.345989  \n",
       "139979  0.883996  0.483994  0.099337  1.341227 -0.175988  0.220853  \n",
       "139980  0.294660  0.613317 -0.278234  1.259872 -0.099662  0.093227  \n",
       "139981  0.130466 -0.347127 -0.497422 -0.857222 -0.358201  0.006298  \n",
       "\n",
       "[139982 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "246ad30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz_trn = 4096\n",
    "batch_sz_val = int(batch_sz_trn / 4)\n",
    "\n",
    "train_dataset = MyDataset(train)\n",
    "val_dataset = MyDataset(val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_sz_trn, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_sz_val, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d4a7d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1266, -0.0371, -0.2418,  0.0321, -0.1173, -0.5373, -0.2734, -0.3704,\n",
       "         0.3557, -0.2544, -1.2157, -0.2559, -0.2192], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "next(data_iter)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dacc0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, output_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim * 2)  # Output mu and logvar\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)  # Output a single value C_s\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = h[:, :latent_dim], h[:, latent_dim:]\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        # Decode\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, mu, logvar\n",
    "\n",
    "output_size = 1\n",
    "input_size = dt.shape[1] - output_size \n",
    "latent_size = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vae = VAE(input_size, latent_size, output_size)\n",
    "vae.to(device)\n",
    "vae.double()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21727075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_function(recon_x, x, mu, logvar):\n",
    "    # Calculate reconstruction loss (MSE)\n",
    "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # Calculate KL divergence\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23be5997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4068.6894736265226\n",
      "Epoch 2, Loss: 4066.9142523023356\n",
      "Epoch 3, Loss: 4066.684731762904\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      5\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      7\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m batch[:, :\u001b[38;5;241m-\u001b[39moutput_size]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Use only the input features\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         targets \u001b[38;5;241m=\u001b[39m batch[:, \u001b[38;5;241m-\u001b[39moutput_size:]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Use the output value C_s\u001b[39;00m\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/lustre07/scratch/hmarefat/torchFOAM/JupyterLab/model_utils.py:25\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Ensure all indices are valid\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata):\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of range for dataset with length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/core/indexing.py:1627\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/core/frame.py:3720\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3718\u001b[0m \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3719\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3720\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_sliced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   3721\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   3722\u001b[0m )\n\u001b[1;32m   3723\u001b[0m result\u001b[38;5;241m.\u001b[39m_set_is_copy(\u001b[38;5;28mself\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   3724\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/core/series.py:359\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    344\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m     fastpath: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    350\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager))\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ):\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;66;03m# GH#33357 called with just the SingleBlockManager\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;66;03m# e.g. from _box_col_values, skip validation of name\u001b[39;00m\n\u001b[1;32m    362\u001b[0m             \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs = batch[:, :-output_size].to(device)  # Use only the input features\n",
    "        targets = batch[:, -output_size:].to(device)  # Use the output value C_s\n",
    "        optimizer.zero_grad()\n",
    "        recon_targets, mu, logvar = vae(inputs)\n",
    "        loss = mse_loss_function(recon_targets, targets, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(vae.state_dict(), 'vae_wavelet.pth')\n",
    "\n",
    "# Evaluate the VAE\n",
    "vae.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = batch[:, :-output_size].to(device)  # Use only the input features\n",
    "        targets = batch[:, -output_size:].to(device)  # Use the output value C_s\n",
    "        recon_targets, mu, logvar = vae(inputs)\n",
    "        loss = mse_loss_function(recon_targets, targets, mu, logvar)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46bb158",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8cd4b6",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e472440",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001949b7",
   "metadata": {},
   "source": [
    "## $\\mathcal Re = 10^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'M1_103': M1_103,\n",
    "    'M2_103': M2_103,\n",
    "    'M3_103': M3_103,\n",
    "    'M4_103': M4_103\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Loop through each dataset and perform calculations and plotting\n",
    "for i, (dt_name, dt) in enumerate(datasets.items()):\n",
    "    print(f\"--- Using this Model Config: {dt_name}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"--- Running on {device}!\")\n",
    "\n",
    "    PATH = f\"./best_model_{dt_name}.pt\"\n",
    "    output_size = 1\n",
    "    input_size = dt.shape[1] - output_size\n",
    "    neurons_per_layer = [60, 60, 60, 60, 60]\n",
    "    hidden_layers = len(neurons_per_layer)\n",
    "    model = MLPModel(input_size=input_size,\n",
    "                     output_size=output_size,\n",
    "                     hidden_layers=hidden_layers,\n",
    "                     neurons_per_layer=neurons_per_layer)\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    model.double()\n",
    "\n",
    "    test = globals()[f\"{dt_name}_test\"]\n",
    "    test_features = test.iloc[:, :-1].values\n",
    "    test_label = test.iloc[:, -1].values\n",
    "    test_features_tensor = torch.tensor(test_features).double().to(device)\n",
    "\n",
    "    Cs_norm_pred = model(test_features_tensor)\n",
    "    Cs_norm = Cs_norm_pred.detach().cpu().numpy()\n",
    "    Cs_tilde = Cs_norm * dSn_R103_unseen_scales['Cs'].values + dSn_R103_unseen_means['Cs'].values\n",
    "    Cs_GT = test_label * dSn_R103_unseen_scales['Cs'].values + dSn_R103_unseen_means['Cs'].values\n",
    "\n",
    "    n, xedges, yedges = np.histogram2d(Cs_GT, Cs_tilde.squeeze(), bins=[1500, 1501])\n",
    "    jpdf = n / trapz(trapz(n, xedges[:-1], axis=0), yedges[:-1])\n",
    "    X, Y = np.meshgrid(xedges[:-1], yedges[:-1])\n",
    "\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    c = ax.pcolormesh(X, Y, jpdf.T, shading='auto', cmap='jet')\n",
    "    c.set_clim([-4, 54])\n",
    "    ax.set_title(f'$\\mathbf M{dt_name[1]}$', fontsize=16)\n",
    "    ax.set_xlabel(r'$C_s$', fontsize=14)\n",
    "    ax.set_ylabel(r'$\\tilde{C_s}$', fontsize=14)\n",
    "    ax.set_xlim([-0.15, 0.15])\n",
    "    ax.set_ylim([-0.15, 0.15])\n",
    "    fig.colorbar(c, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e97879",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Loop through each dataset and perform calculations and plotting\n",
    "for i, (dt_name, dt) in enumerate(datasets.items()):\n",
    "    print(f\"--- Using this Model Config: {dt_name}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"--- Running on {device}!\")\n",
    "\n",
    "    PATH = f\"./best_model_{dt_name}.pt\"\n",
    "    output_size = 1\n",
    "    input_size = dt.shape[1] - output_size\n",
    "    neurons_per_layer = [60, 60, 60, 60, 60]\n",
    "    hidden_layers = len(neurons_per_layer)\n",
    "    model = MLPModel(input_size=input_size,\n",
    "                     output_size=output_size,\n",
    "                     hidden_layers=hidden_layers,\n",
    "                     neurons_per_layer=neurons_per_layer)\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    model.double()\n",
    "\n",
    "    test = globals()[f\"{dt_name}_test\"]\n",
    "    test_features = test.iloc[:, :-1].values\n",
    "    test_label = test.iloc[:, -1].values\n",
    "    test_features_tensor = torch.tensor(test_features).double().to(device)\n",
    "\n",
    "    Cs_norm_pred = model(test_features_tensor)\n",
    "    Cs_norm = Cs_norm_pred.detach().cpu().numpy()\n",
    "    Cs_tilde = Cs_norm * dSn_R103_unseen_scales['Cs'].values + dSn_R103_unseen_means['Cs'].values\n",
    "    Cs_GT = test_label * dSn_R103_unseen_scales['Cs'].values + dSn_R103_unseen_means['Cs'].values\n",
    "\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.scatter(Cs_GT, Cs_tilde.squeeze(), edgecolor='white', color='red')\n",
    "    ax.set_title(f'{dt_name}', fontsize=14)\n",
    "    ax.set_xlabel(r'$C_s$', fontsize=12)\n",
    "    ax.set_ylabel(r'$\\tilde{C_s}$', fontsize=12)\n",
    "    ax.set_xlim([-1, 1])\n",
    "    ax.set_ylim([-1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffb8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03946093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a9867ed",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f56c7",
   "metadata": {},
   "source": [
    "## $\\mathcal Re = 5 \\times 10^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a500be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'M1_503': M1_503,\n",
    "    'M2_503': M2_503,\n",
    "    'M3_503': M3_503,\n",
    "    'M4_503': M4_503\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Loop through each dataset and perform calculations and plotting\n",
    "for i, (dt_name, dt) in enumerate(datasets.items()):\n",
    "    print(f\"--- Using this Model Config: {dt_name}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"--- Running on {device}!\")\n",
    "\n",
    "    PATH = f\"./best_model_{dt_name}.pt\"\n",
    "    output_size = 1\n",
    "    input_size = dt.shape[1] - output_size\n",
    "    neurons_per_layer = [60, 60, 60, 60, 60]\n",
    "    hidden_layers = len(neurons_per_layer)\n",
    "    model = MLPModel(input_size=input_size,\n",
    "                     output_size=output_size,\n",
    "                     hidden_layers=hidden_layers,\n",
    "                     neurons_per_layer=neurons_per_layer)\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    model.double()\n",
    "\n",
    "    test = globals()[f\"{dt_name}_test\"]\n",
    "    test_features = test.iloc[:, :-1].values\n",
    "    test_label = test.iloc[:, -1].values\n",
    "    test_features_tensor = torch.tensor(test_features).double().to(device)\n",
    "\n",
    "    Cs_norm_pred = model(test_features_tensor)\n",
    "    Cs_norm = Cs_norm_pred.detach().cpu().numpy()\n",
    "    Cs_tilde = Cs_norm * dSn_R503_unseen_scales['Cs'].values + dSn_R503_unseen_means['Cs'].values\n",
    "    Cs_GT = test_label * dSn_R503_unseen_scales['Cs'].values + dSn_R503_unseen_means['Cs'].values\n",
    "\n",
    "    n, xedges, yedges = np.histogram2d(Cs_GT, Cs_tilde.squeeze(), bins=[1500, 1501])\n",
    "    jpdf = n / trapz(trapz(n, xedges[:-1], axis=0), yedges[:-1])\n",
    "    X, Y = np.meshgrid(xedges[:-1], yedges[:-1])\n",
    "\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    c = ax.pcolormesh(X, Y, jpdf.T, shading='auto', cmap='jet')\n",
    "    c.set_clim([-4, 54])\n",
    "    ax.set_title(f'$\\mathbf M{dt_name[1]}$', fontsize=16)\n",
    "    ax.set_xlabel(r'$C_s$', fontsize=14)\n",
    "    ax.set_ylabel(r'$\\tilde{C_s}$', fontsize=14)\n",
    "    ax.set_xlim([-0.15, 0.15])\n",
    "    ax.set_ylim([-0.15, 0.15])\n",
    "    fig.colorbar(c, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b961a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd466a46",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f7188",
   "metadata": {},
   "source": [
    "## $\\mathcal Re = 10^4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406668a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'M1_104': M1_104,\n",
    "    'M2_104': M2_104,\n",
    "    'M3_104': M3_104,\n",
    "    'M4_104': M4_104\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Loop through each dataset and perform calculations and plotting\n",
    "for i, (dt_name, dt) in enumerate(datasets.items()):\n",
    "    print(f\"--- Using this Model Config: {dt_name}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"--- Running on {device}!\")\n",
    "\n",
    "    PATH = f\"./best_model_{dt_name}.pt\"\n",
    "    output_size = 1\n",
    "    input_size = dt.shape[1] - output_size\n",
    "    neurons_per_layer = [60, 60, 60, 60, 60]\n",
    "    hidden_layers = len(neurons_per_layer)\n",
    "    model = MLPModel(input_size=input_size,\n",
    "                     output_size=output_size,\n",
    "                     hidden_layers=hidden_layers,\n",
    "                     neurons_per_layer=neurons_per_layer)\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    model.double()\n",
    "\n",
    "    test = globals()[f\"{dt_name}_test\"]\n",
    "    test_features = test.iloc[:, :-1].values\n",
    "    test_label = test.iloc[:, -1].values\n",
    "    test_features_tensor = torch.tensor(test_features).double().to(device)\n",
    "\n",
    "    Cs_norm_pred = model(test_features_tensor)\n",
    "    Cs_norm = Cs_norm_pred.detach().cpu().numpy()\n",
    "    Cs_tilde = Cs_norm * dSn_R104_unseen_scales['Cs'].values + dSn_R104_unseen_means['Cs'].values\n",
    "    Cs_GT = test_label * dSn_R104_unseen_scales['Cs'].values + dSn_R104_unseen_means['Cs'].values\n",
    "\n",
    "    n, xedges, yedges = np.histogram2d(Cs_GT, Cs_tilde.squeeze(), bins=[1500, 1501])\n",
    "    jpdf = n / trapz(trapz(n, xedges[:-1], axis=0), yedges[:-1])\n",
    "    X, Y = np.meshgrid(xedges[:-1], yedges[:-1])\n",
    "\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    c = ax.pcolormesh(X, Y, jpdf.T, shading='auto', cmap='jet')\n",
    "    c.set_clim([-4, 54])\n",
    "    ax.set_title(f'$\\mathbf M{dt_name[1]}$', fontsize=16)\n",
    "    ax.set_xlabel(r'$C_s$', fontsize=14)\n",
    "    ax.set_ylabel(r'$\\tilde{C_s}$', fontsize=14)\n",
    "    ax.set_xlim([-0.15, 0.15])\n",
    "    ax.set_ylim([-0.15, 0.15])\n",
    "    fig.colorbar(c, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e3177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
