{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d783e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys_epsilon = sys.float_info.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56a97af",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/fieldData_R103_means.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m R103_means \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./datasets/fieldData_R103_means.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mset_axis(headers, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m R503_means \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/fieldData_R503_means.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mset_axis(headers, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m R104_means \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/fieldData_R104_means.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mset_axis(headers, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/jupEnv/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/fieldData_R103_means.txt'"
     ]
    }
   ],
   "source": [
    "R103_means = pd.read_csv('./datasets/fieldData_R103_means.txt', sep=' ', header=None).T.set_axis(headers, axis=1)\n",
    "R503_means = pd.read_csv('./datasets/fieldData_R503_means.txt', sep=' ', header=None).T.set_axis(headers, axis=1)\n",
    "R104_means = pd.read_csv('./datasets/fieldData_R104_means.txt', sep=' ', header=None).T.set_axis(headers, axis=1)\n",
    "\n",
    "R103_scales = pd.read_csv('./datasets/fieldData_R103_scales.txt', sep=' ', header=None).T.set_axis(headers, axis=1)\n",
    "R503_scales = pd.read_csv('./datasets/fieldData_R503_scales.txt', sep=' ', header=None).T.set_axis(headers, axis=1)\n",
    "R104_scales = pd.read_csv('./datasets/fieldData_R104_scales.txt', sep=' ', header=None).T.set_axis(headers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b9b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"t\", \"Ux\", \"Uy\", \"Uz\", \n",
    "           \"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\", \n",
    "           \"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \n",
    "           \"UUp1\", \"UUp2\", \"UUp3\", \"UUp4\", \"UUp5\", \"UUp6\", \n",
    "           \"Cs\"]\n",
    "\n",
    "R103 = pd.read_csv('./datasets/fieldData_R103_norm.txt', sep=' ', names=headers)\n",
    "R503 = pd.read_csv('./datasets/fieldData_R503_norm.txt', sep=' ', names=headers)\n",
    "R104 = pd.read_csv('./datasets/fieldData_R104_norm.txt', sep=' ', names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab61fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>Ux</th>\n",
       "      <th>Uy</th>\n",
       "      <th>Uz</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>G4</th>\n",
       "      <th>G5</th>\n",
       "      <th>G6</th>\n",
       "      <th>...</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>UUp1</th>\n",
       "      <th>UUp2</th>\n",
       "      <th>UUp3</th>\n",
       "      <th>UUp4</th>\n",
       "      <th>UUp5</th>\n",
       "      <th>UUp6</th>\n",
       "      <th>Cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.027122</td>\n",
       "      <td>-0.000607</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>-0.004942</td>\n",
       "      <td>-0.002082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004942</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.001784</td>\n",
       "      <td>-0.134213</td>\n",
       "      <td>-0.010852</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>-0.153644</td>\n",
       "      <td>-0.045258</td>\n",
       "      <td>-0.150407</td>\n",
       "      <td>-0.232084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.027122</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.021788</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>-0.017760</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017760</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.015981</td>\n",
       "      <td>-0.134199</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>-0.153644</td>\n",
       "      <td>-0.045258</td>\n",
       "      <td>-0.150407</td>\n",
       "      <td>-0.191414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.027122</td>\n",
       "      <td>0.146858</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-0.133998</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>-0.153644</td>\n",
       "      <td>-0.045258</td>\n",
       "      <td>-0.150406</td>\n",
       "      <td>0.044781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.027122</td>\n",
       "      <td>0.095208</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>-0.003282</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>-0.002076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>-0.133893</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>-0.153644</td>\n",
       "      <td>-0.045258</td>\n",
       "      <td>-0.150406</td>\n",
       "      <td>0.088803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.027122</td>\n",
       "      <td>0.078927</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.002077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>-0.133738</td>\n",
       "      <td>-0.010855</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>-0.153644</td>\n",
       "      <td>-0.045258</td>\n",
       "      <td>-0.150406</td>\n",
       "      <td>-0.099000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          t        Ux        Uy        Uz        G1        G2        G3  \\\n",
       "0 -1.027122 -0.000607 -0.001033  0.001586  0.003769 -0.000243 -0.000310   \n",
       "1 -1.027122  0.048423 -0.002944 -0.000262  0.021788 -0.000289 -0.000408   \n",
       "2 -1.027122  0.146858 -0.000820  0.001179  0.005336  0.000219  0.000182   \n",
       "3 -1.027122  0.095208 -0.000137  0.002144 -0.003282 -0.000302 -0.000333   \n",
       "4 -1.027122  0.078927 -0.000084  0.001453 -0.000148 -0.000061 -0.000199   \n",
       "\n",
       "         G4        G5        G6  ...        S4        S5        S6      UUp1  \\\n",
       "0  0.001519 -0.004942 -0.002082  ... -0.004942  0.000056 -0.001784 -0.134213   \n",
       "1  0.001519 -0.017760 -0.002090  ... -0.017760  0.000042 -0.015981 -0.134199   \n",
       "2  0.001882 -0.003509 -0.002079  ... -0.003509  0.000060 -0.004908 -0.133998   \n",
       "3  0.001519  0.001063 -0.002076  ...  0.001063  0.000066  0.002495 -0.133893   \n",
       "4  0.001519  0.001425 -0.002077  ...  0.001425  0.000064 -0.002813 -0.133738   \n",
       "\n",
       "       UUp2      UUp3      UUp4      UUp5      UUp6        Cs  \n",
       "0 -0.010852  0.009912 -0.153644 -0.045258 -0.150407 -0.232084  \n",
       "1 -0.010853  0.009911 -0.153644 -0.045258 -0.150407 -0.191414  \n",
       "2 -0.010854  0.009910 -0.153644 -0.045258 -0.150406  0.044781  \n",
       "3 -0.010854  0.009910 -0.153644 -0.045258 -0.150406  0.088803  \n",
       "4 -0.010855  0.009909 -0.153644 -0.045258 -0.150406 -0.099000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R103.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5190ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26697608, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [R103, R503, R104]\n",
    "df = pd.concat(frames)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00708509",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_headers = ['Ux', 'Uy', 'Uz', 'S1',  'S2', 'S3', 'S4', 'S5', 'S6', 'Cs']\n",
    "M2_headers = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'S1',  'S2', 'S3', 'S4', 'S5', 'S6', 'Cs']\n",
    "M3_headers = ['Ux', 'Uy', 'Uz', 'UUp1',  'UUp2', 'UUp3', 'UUp4', 'UUp5', 'UUp6', 'Cs']\n",
    "M4_headers = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'UUp1',  'UUp2', 'UUp3', 'UUp4', 'UUp5', 'UUp6', 'Cs']\n",
    "\n",
    "M1_103 = R103.filter(M1_headers, axis=1)\n",
    "M2_103 = R103.filter(M2_headers, axis=1)\n",
    "M3_103 = R103.filter(M3_headers, axis=1)\n",
    "M4_103 = R103.filter(M4_headers, axis=1)\n",
    "\n",
    "M1_503 = R503.filter(M1_headers, axis=1)\n",
    "M2_503 = R503.filter(M2_headers, axis=1)\n",
    "M3_503 = R503.filter(M3_headers, axis=1)\n",
    "M4_503 = R503.filter(M4_headers, axis=1)\n",
    "\n",
    "M1_104 = R104.filter(M1_headers, axis=1)\n",
    "M2_104 = R104.filter(M2_headers, axis=1)\n",
    "M3_104 = R104.filter(M3_headers, axis=1)\n",
    "M4_104 = R104.filter(M4_headers, axis=1)\n",
    "\n",
    "M1 = df.filter(M1_headers, axis=1)\n",
    "M2 = df.filter(M2_headers, axis=1)\n",
    "M3 = df.filter(M3_headers, axis=1)\n",
    "M4 = df.filter(M4_headers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f89e529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26697608, 10), (26697608, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1.shape, M2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f891aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5816028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = R104_scales[\"Cs\"]\n",
    "mean = R104_means[\"Cs\"]\n",
    "dt = M4_104\n",
    "dt_name = namestr(M4_104, globals())[0]\n",
    "output_size = 1\n",
    "input_size = dt.shape[1] - output_size \n",
    "neurons_per_layer = [60, 60, 60, 60, 60] #[120, 60, 30, 20, 10, 10, 20, 30, 60]\n",
    "hidden_layers = len(neurons_per_layer)   \n",
    "#latent_size = 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9321b395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>G4</th>\n",
       "      <th>G5</th>\n",
       "      <th>G6</th>\n",
       "      <th>UUp1</th>\n",
       "      <th>UUp2</th>\n",
       "      <th>UUp3</th>\n",
       "      <th>UUp4</th>\n",
       "      <th>UUp5</th>\n",
       "      <th>UUp6</th>\n",
       "      <th>Cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000859</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>-0.117743</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>-0.143908</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>-0.143157</td>\n",
       "      <td>-1.929617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.004601</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>-0.117742</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>-0.143908</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>-0.143157</td>\n",
       "      <td>-0.183021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015995</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>-0.117735</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>-0.143908</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>-0.143157</td>\n",
       "      <td>-0.124142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011368</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.117709</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>-0.143908</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>-0.143157</td>\n",
       "      <td>-0.258416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009122</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>-0.001645</td>\n",
       "      <td>-0.117683</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>-0.143908</td>\n",
       "      <td>-0.005118</td>\n",
       "      <td>-0.143157</td>\n",
       "      <td>0.106165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         G1        G2        G3        G4        G5        G6      UUp1  \\\n",
       "0 -0.000859  0.001333  0.000589  0.000236 -0.001709  0.000490 -0.117743   \n",
       "1  0.007403  0.001420  0.000656  0.000236 -0.004601  0.000669 -0.117742   \n",
       "2  0.015995  0.001564  0.000896  0.000236 -0.008244 -0.000488 -0.117735   \n",
       "3  0.011368  0.001738  0.001067  0.000236 -0.001409 -0.001457 -0.117709   \n",
       "4 -0.009122  0.000399  0.000139 -0.000411  0.004366 -0.001645 -0.117683   \n",
       "\n",
       "       UUp2      UUp3      UUp4      UUp5      UUp6        Cs  \n",
       "0 -0.001035  0.000682 -0.143908 -0.005119 -0.143157 -1.929617  \n",
       "1 -0.001035  0.000682 -0.143908 -0.005119 -0.143157 -0.183021  \n",
       "2 -0.001036  0.000682 -0.143908 -0.005119 -0.143157 -0.124142  \n",
       "3 -0.001036  0.000681 -0.143908 -0.005119 -0.143157 -0.258416  \n",
       "4 -0.001036  0.000681 -0.143908 -0.005118 -0.143157  0.106165  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe61abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt.to_csv(f'./{dt_name}.txt', sep=' ', index=False, encoding='utf-8', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa94eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(dt)) < 0.8\n",
    "train_val = dt[mask]\n",
    "test = dt[~mask].to_numpy()\n",
    "\n",
    "mask = np.random.rand(len(train_val)) < 0.8\n",
    "train = train_val[mask].to_numpy()\n",
    "val = train_val[~mask].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5586cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17552029, 13), 11234695, 2807427, 3509907)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape, train.shape[0], val.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15cbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz_trn = 4096\n",
    "batch_sz_val = int(batch_sz_trn / 4)\n",
    "batch_sz_tst = int(batch_sz_trn / 4)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_sz_trn, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batch_sz_val, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_sz_tst, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "364d96fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5163e-02, -8.0394e-03, -1.9024e-03, -4.2935e-03,  1.9647e-02,\n",
       "        -7.3606e-03, -1.1723e-01, -1.0461e-03,  7.3754e-04, -1.4345e-01,\n",
       "        -4.8394e-03, -1.4298e-01, -8.1433e-01], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "next(data_iter)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854d19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res = torch.sum(torch.square( y_true - y_pred ))\n",
    "    SS_tot = torch.sum(torch.square( y_true - torch.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + sys_epsilon) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7b91edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, neurons_per_layer):\n",
    "        super(MLPModel, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, neurons_per_layer[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for i in range(1, hidden_layers):\n",
    "            layers.append(nn.Linear(neurons_per_layer[i - 1], neurons_per_layer[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(neurons_per_layer[-1], output_size))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b59a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, hidden_layers, neurons_per_layer):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        encoder_layers = []\n",
    "        encoder_layers.append(nn.Linear(input_size, neurons_per_layer[0]))\n",
    "        encoder_layers.append(nn.ReLU())\n",
    "\n",
    "        for i in range(1, hidden_layers):\n",
    "            encoder_layers.append(nn.Linear(neurons_per_layer[i - 1], neurons_per_layer[i]))\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "\n",
    "        encoder_layers.append(nn.Linear(neurons_per_layer[-1], latent_size))\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        # Decoder layers\n",
    "        decoder_layers = []\n",
    "        decoder_layers.append(nn.Linear(latent_size, neurons_per_layer[-1]))\n",
    "        decoder_layers.append(nn.ReLU())\n",
    "\n",
    "        for i in range(hidden_layers - 1, 0, -1):\n",
    "            decoder_layers.append(nn.Linear(neurons_per_layer[i], neurons_per_layer[i - 1]))\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "\n",
    "        decoder_layers.append(nn.Linear(neurons_per_layer[0], 1))\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode input\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        # Decode\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85bbb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(input_size=input_size, \n",
    "                 output_size=output_size, \n",
    "                 hidden_layers=hidden_layers, \n",
    "                 neurons_per_layer=neurons_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "564817d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Autoencoder(input_size, latent_size, hidden_layers, neurons_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19be546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "184f47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.MSELoss()  # Mean Squared Error loss for reconstruction\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6152899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPModel(\n",
       "  (block): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=60, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=60, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1173ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, path=None):\n",
    "        self.patience = patience\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.min_val_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, model_stat, val_loss):\n",
    "        if val_loss < self.min_val_loss:\n",
    "            torch.save(model_stat, self.path)\n",
    "            self.min_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss > (self.min_val_loss + sys_epsilon):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print('+++ Early Stopping is reached! +++')\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82eab4ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 64.03batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 6000, \n",
      " Train -- Loss: 0.6223813256101323, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.353805321026261, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.14batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 238.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 6000, \n",
      " Train -- Loss: 0.6066980500418006, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.3181211950565426, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.86batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 6000, \n",
      " Train -- Loss: 0.5998018649233893, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.3046816936417063, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.11batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 6000, \n",
      " Train -- Loss: 0.5939638229764839, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2794590190571036, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.92batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 6000, \n",
      " Train -- Loss: 0.5891169316530369, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2558538862055406, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.46batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / 6000, \n",
      " Train -- Loss: 0.5855060351260648, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.265980476595093, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:40<00:00, 67.22batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / 6000, \n",
      " Train -- Loss: 0.5830325994885495, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.247522330320236, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.58batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / 6000, \n",
      " Train -- Loss: 0.581086988551249, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.25199994622655, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.81batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 6000, \n",
      " Train -- Loss: 0.5793766674369437, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2468873908959495, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.05batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 238.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / 6000, \n",
      " Train -- Loss: 0.5777671810525378, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.233263795316538, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.06batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 / 6000, \n",
      " Train -- Loss: 0.5763517395987374, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2358237656859163, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.13batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 / 6000, \n",
      " Train -- Loss: 0.5751928095726595, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2357351319141427, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.58batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 / 6000, \n",
      " Train -- Loss: 0.5737132073109202, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2328057842674505, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.47batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 / 6000, \n",
      " Train -- Loss: 0.572540314800677, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2705429391255976, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.37batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 / 6000, \n",
      " Train -- Loss: 0.5717557363596916, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.21199887755059, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.37batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 / 6000, \n",
      " Train -- Loss: 0.5705619265501459, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.219567948737515, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.99batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 / 6000, \n",
      " Train -- Loss: 0.569582960140722, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2227680167729975, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.65batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 / 6000, \n",
      " Train -- Loss: 0.5686922392599579, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2196325303570124, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.53batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 / 6000, \n",
      " Train -- Loss: 0.567381774977035, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.215389256203486, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.39batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 / 6000, \n",
      " Train -- Loss: 0.5667099739487786, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2127736363177375, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.48batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 / 6000, \n",
      " Train -- Loss: 0.5660186158147774, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2259439731692687, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.01batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 / 6000, \n",
      " Train -- Loss: 0.5653268511551465, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2162297156090416, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 65.20batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 / 6000, \n",
      " Train -- Loss: 0.564564174541512, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.195964267066436, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.50batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 / 6000, \n",
      " Train -- Loss: 0.5640546346406486, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.205390922669949, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 65.06batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 / 6000, \n",
      " Train -- Loss: 0.5627163613603162, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.224147467121413, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 65.27batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 / 6000, \n",
      " Train -- Loss: 0.5634162439643104, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.194902879806097, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:40<00:00, 68.57batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 / 6000, \n",
      " Train -- Loss: 0.5617650321729812, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1959190538778097, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.16batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 / 6000, \n",
      " Train -- Loss: 0.5610384472086147, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.205251818575711, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.80batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 / 6000, \n",
      " Train -- Loss: 0.5608391409053032, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.200425186304036, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 65.15batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 238.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 / 6000, \n",
      " Train -- Loss: 0.5599842091076441, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2078839787084408, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.28batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 / 6000, \n",
      " Train -- Loss: 0.5592466130671175, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.197557660446334, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.76batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 / 6000, \n",
      " Train -- Loss: 0.5594943645082171, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2118361543392457, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.92batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 / 6000, \n",
      " Train -- Loss: 0.559015053763386, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2062710197792925, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.59batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 / 6000, \n",
      " Train -- Loss: 0.5576053977958224, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1952639895782684, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.79batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 243.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 / 6000, \n",
      " Train -- Loss: 0.5570030617221412, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1947196467265924, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 65.21batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 / 6000, \n",
      " Train -- Loss: 0.5576579143999123, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.186134926412006, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.94batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 / 6000, \n",
      " Train -- Loss: 0.5564607690679066, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1865719619597783, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.36batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 / 6000, \n",
      " Train -- Loss: 0.5567103912277878, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1947145305882776, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 65.24batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 / 6000, \n",
      " Train -- Loss: 0.5564491109096306, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.191011912205829, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.75batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 / 6000, \n",
      " Train -- Loss: 0.5557573201563378, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1973178927212533, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.49batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 / 6000, \n",
      " Train -- Loss: 0.555393056765511, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.201224177559546, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.68batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 / 6000, \n",
      " Train -- Loss: 0.554456004281541, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.187683028347542, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 65.29batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 / 6000, \n",
      " Train -- Loss: 0.5547243917686103, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1950626029250517, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.52batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 / 6000, \n",
      " Train -- Loss: 0.5544177486035772, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.179904300730175, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.58batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 / 6000, \n",
      " Train -- Loss: 0.5539845732518999, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.191408343500154, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.08batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 / 6000, \n",
      " Train -- Loss: 0.5535490076312567, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1842303434005674, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.02batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 / 6000, \n",
      " Train -- Loss: 0.5527254867324288, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1990835026284703, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.87batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 239.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 / 6000, \n",
      " Train -- Loss: 0.5522675368867614, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1916920793664816, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.90batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 / 6000, \n",
      " Train -- Loss: 0.5526536680700948, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1816696434747564, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.06batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 / 6000, \n",
      " Train -- Loss: 0.5518893574312367, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.18038810568759, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.69batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 / 6000, \n",
      " Train -- Loss: 0.5523621111176407, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.19153335935015, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.40batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 / 6000, \n",
      " Train -- Loss: 0.5514411687559712, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1896489952956926, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.63batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 239.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 / 6000, \n",
      " Train -- Loss: 0.5516989350443325, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1894714214663304, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.77batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 / 6000, \n",
      " Train -- Loss: 0.5512744230538615, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1772082234802, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.03batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 / 6000, \n",
      " Train -- Loss: 0.5500821076505237, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1740321455654925, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.66batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 / 6000, \n",
      " Train -- Loss: 0.5500307284324253, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1809595285063574, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.20batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 / 6000, \n",
      " Train -- Loss: 0.5500334244232611, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.191122569045778, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.79batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 238.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 / 6000, \n",
      " Train -- Loss: 0.5496435757859615, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1844427706484084, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.61batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 / 6000, \n",
      " Train -- Loss: 0.5499257809708058, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.175008582021906, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.34batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 / 6000, \n",
      " Train -- Loss: 0.5491681009382091, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1737431551690154, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.96batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 / 6000, \n",
      " Train -- Loss: 0.5493193677475818, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1707312905309086, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:42<00:00, 63.95batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 / 6000, \n",
      " Train -- Loss: 0.5484858690422936, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1922029411715567, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.01batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 / 6000, \n",
      " Train -- Loss: 0.5489217761745676, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.184336208646612, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:40<00:00, 67.16batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 / 6000, \n",
      " Train -- Loss: 0.5482444591773229, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.182538363644365, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.00batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 / 6000, \n",
      " Train -- Loss: 0.5482798670944363, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.193617605313346, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.77batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 / 6000, \n",
      " Train -- Loss: 0.5479182435066701, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1766998643324733, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.27batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 / 6000, \n",
      " Train -- Loss: 0.5478010967945117, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.177240134466625, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.76batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 238.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 / 6000, \n",
      " Train -- Loss: 0.5471948311423607, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1959487785789493, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.68batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 / 6000, \n",
      " Train -- Loss: 0.5472451335511117, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1724548648438096, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.96batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 / 6000, \n",
      " Train -- Loss: 0.5470209333955235, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.181224326690104, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.59batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 / 6000, \n",
      " Train -- Loss: 0.5463201060963694, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.17028259268515, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.97batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71 / 6000, \n",
      " Train -- Loss: 0.5461364642360248, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1801490808776984, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:43<00:00, 62.53batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 / 6000, \n",
      " Train -- Loss: 0.5458711851293282, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1702767302884234, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.48batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 / 6000, \n",
      " Train -- Loss: 0.5463145988312629, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1765386450185713, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.42batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 / 6000, \n",
      " Train -- Loss: 0.5462848341634228, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1896680325531896, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.99batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 / 6000, \n",
      " Train -- Loss: 0.5455498249271863, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1727592169216488, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.95batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76 / 6000, \n",
      " Train -- Loss: 0.5463222466702972, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1762271635604167, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.72batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 / 6000, \n",
      " Train -- Loss: 0.5453927567326609, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1825715891679636, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.57batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 / 6000, \n",
      " Train -- Loss: 0.5446834285995186, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1659529120021044, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.08batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79 / 6000, \n",
      " Train -- Loss: 0.5444517132204564, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1754021579657192, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.02batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 / 6000, \n",
      " Train -- Loss: 0.5445963594032651, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.2105643947462594, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.10batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 / 6000, \n",
      " Train -- Loss: 0.5448477824353686, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1995952715129397, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.83batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 / 6000, \n",
      " Train -- Loss: 0.5442434241723751, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1715847284171095, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.83batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83 / 6000, \n",
      " Train -- Loss: 0.5438696792955079, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1799357275509252, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.06batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 / 6000, \n",
      " Train -- Loss: 0.5442674462334393, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.181595876904007, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.55batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 / 6000, \n",
      " Train -- Loss: 0.543457705786816, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.170629931735511, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.20batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 / 6000, \n",
      " Train -- Loss: 0.5440466589148584, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.177511873459416, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.77batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 / 6000, \n",
      " Train -- Loss: 0.5435279856128459, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1966135544099665, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.84batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88 / 6000, \n",
      " Train -- Loss: 0.5427999076783603, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.178625157985313, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.33batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89 / 6000, \n",
      " Train -- Loss: 0.5438584127581977, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1760992186289467, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.88batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 / 6000, \n",
      " Train -- Loss: 0.5426976403777046, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.183978298497772, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.76batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91 / 6000, \n",
      " Train -- Loss: 0.5432480379006746, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1691045913013522, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.81batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 / 6000, \n",
      " Train -- Loss: 0.5429925288001916, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1806110931687384, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.42batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93 / 6000, \n",
      " Train -- Loss: 0.5422759757467992, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1964515008772225, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.07batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94 / 6000, \n",
      " Train -- Loss: 0.5424345652688162, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.171868943437574, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.65batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95 / 6000, \n",
      " Train -- Loss: 0.5426346251012188, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1773271614937126, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.75batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96 / 6000, \n",
      " Train -- Loss: 0.5420347500837283, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.174799597115431, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.08batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 / 6000, \n",
      " Train -- Loss: 0.541915240576757, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1742442896900878, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.85batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 / 6000, \n",
      " Train -- Loss: 0.542126395522749, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.175205548047391, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.08batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99 / 6000, \n",
      " Train -- Loss: 0.5412654942457753, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.179776987148753, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.27batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 / 6000, \n",
      " Train -- Loss: 0.5413187208246271, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.168546833985761, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:40<00:00, 67.11batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101 / 6000, \n",
      " Train -- Loss: 0.5415024857765635, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.167933775312351, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.86batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102 / 6000, \n",
      " Train -- Loss: 0.5412334255463378, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.17881508989251, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.20batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103 / 6000, \n",
      " Train -- Loss: 0.5409428491897695, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1801002101297406, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.79batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104 / 6000, \n",
      " Train -- Loss: 0.5409392089012782, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.18033675573743, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.48batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105 / 6000, \n",
      " Train -- Loss: 0.5407191133483271, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1686105126723434, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.98batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106 / 6000, \n",
      " Train -- Loss: 0.5409616382671606, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.172946033792798, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.27batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 231.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107 / 6000, \n",
      " Train -- Loss: 0.5407406914314603, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.168477819851058, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.96batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108 / 6000, \n",
      " Train -- Loss: 0.5408047079717521, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1745583695307085, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.96batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109 / 6000, \n",
      " Train -- Loss: 0.5397046518282806, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.177512965939139, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.74batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110 / 6000, \n",
      " Train -- Loss: 0.5403439118631568, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1809754600143645, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.51batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111 / 6000, \n",
      " Train -- Loss: 0.5397053599905487, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.169880249229046, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.97batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112 / 6000, \n",
      " Train -- Loss: 0.5397691697650093, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.173201131306227, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.67batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113 / 6000, \n",
      " Train -- Loss: 0.5396339922670154, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1669081423771646, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.13batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114 / 6000, \n",
      " Train -- Loss: 0.53915552338621, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.193825828647705, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.61batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115 / 6000, \n",
      " Train -- Loss: 0.5397746849297116, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1858968707950575, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.73batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116 / 6000, \n",
      " Train -- Loss: 0.5399976188003418, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1665920920803097, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.17batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 117 / 6000, \n",
      " Train -- Loss: 0.5399713264326059, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.188569191827868, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.74batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118 / 6000, \n",
      " Train -- Loss: 0.5389200925533292, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1786022692835205, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.17batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 231.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119 / 6000, \n",
      " Train -- Loss: 0.5397630374950088, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.185004989451377, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.11batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 / 6000, \n",
      " Train -- Loss: 0.5385928578971423, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.18087627661761, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.81batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121 / 6000, \n",
      " Train -- Loss: 0.5388967268893046, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1675579684896356, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.03batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122 / 6000, \n",
      " Train -- Loss: 0.5384411307330079, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1739735802613613, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.68batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123 / 6000, \n",
      " Train -- Loss: 0.5385280133587915, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1696469678578527, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.01batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124 / 6000, \n",
      " Train -- Loss: 0.5387364039106318, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1758177289320226, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.86batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125 / 6000, \n",
      " Train -- Loss: 0.5381477101875666, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1948482476478133, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.31batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126 / 6000, \n",
      " Train -- Loss: 0.5380240320661818, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1721134576218124, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.99batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127 / 6000, \n",
      " Train -- Loss: 0.537864059822169, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.156302314322251, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.55batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128 / 6000, \n",
      " Train -- Loss: 0.5380980863954493, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.169084250883681, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.03batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129 / 6000, \n",
      " Train -- Loss: 0.5386997471316314, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1841922654981523, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.10batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130 / 6000, \n",
      " Train -- Loss: 0.5378583544885781, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.171703540855957, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.82batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131 / 6000, \n",
      " Train -- Loss: 0.5374712640760132, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.169529084930855, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.05batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132 / 6000, \n",
      " Train -- Loss: 0.5380393200711086, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1814050558477334, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.58batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133 / 6000, \n",
      " Train -- Loss: 0.5371947138017084, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.16998708206601, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:46<00:00, 58.41batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 230.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134 / 6000, \n",
      " Train -- Loss: 0.537468753491808, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1699455809158166, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.85batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135 / 6000, \n",
      " Train -- Loss: 0.537038955427635, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.173747023927491, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.60batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136 / 6000, \n",
      " Train -- Loss: 0.5366505942770735, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.176184594510278, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.88batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137 / 6000, \n",
      " Train -- Loss: 0.5369162147954369, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.177006144268656, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.89batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138 / 6000, \n",
      " Train -- Loss: 0.5363907969052604, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1872529223483497, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.67batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139 / 6000, \n",
      " Train -- Loss: 0.5368752655851253, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1857121333853593, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.95batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 / 6000, \n",
      " Train -- Loss: 0.5374172077630297, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1684192167638114, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.68batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 231.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141 / 6000, \n",
      " Train -- Loss: 0.5364220777358997, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.179488707448158, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.64batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 142 / 6000, \n",
      " Train -- Loss: 0.5367489792696586, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1854957067455905, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.88batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 / 6000, \n",
      " Train -- Loss: 0.5362410425129079, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.175813035090563, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.77batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144 / 6000, \n",
      " Train -- Loss: 0.5356463814905675, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1932467486605924, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.43batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145 / 6000, \n",
      " Train -- Loss: 0.5359264873767079, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1606370394347025, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.42batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146 / 6000, \n",
      " Train -- Loss: 0.5356162088316428, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.174342372291915, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.84batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147 / 6000, \n",
      " Train -- Loss: 0.5364278152358255, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1614397207590073, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.37batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 231.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148 / 6000, \n",
      " Train -- Loss: 0.5366479461051344, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1699656301334733, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.82batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149 / 6000, \n",
      " Train -- Loss: 0.5360395840596124, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1833986169322004, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.94batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150 / 6000, \n",
      " Train -- Loss: 0.5360522626668348, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.169216057312361, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.37batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151 / 6000, \n",
      " Train -- Loss: 0.5351030191490125, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1596871490575427, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.81batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 152 / 6000, \n",
      " Train -- Loss: 0.5354364089034053, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1639257165343353, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.53batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153 / 6000, \n",
      " Train -- Loss: 0.5355540232445789, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1671832045963297, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.80batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 154 / 6000, \n",
      " Train -- Loss: 0.5364491547467747, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1791531203363403, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.73batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155 / 6000, \n",
      " Train -- Loss: 0.5350825219890336, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.163647466788895, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.00batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156 / 6000, \n",
      " Train -- Loss: 0.5351465379598348, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.159417259504182, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:39<00:00, 69.24batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 238.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 157 / 6000, \n",
      " Train -- Loss: 0.534834343852482, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1673046860361755, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.67batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 234.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 158 / 6000, \n",
      " Train -- Loss: 0.5353079115878849, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.175365858745883, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.88batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159 / 6000, \n",
      " Train -- Loss: 0.5354782208924789, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.174591328338316, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.52batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160 / 6000, \n",
      " Train -- Loss: 0.5346729194007779, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.15951712588052, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.85batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161 / 6000, \n",
      " Train -- Loss: 0.5357942416711927, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1694638264084998, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.15batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162 / 6000, \n",
      " Train -- Loss: 0.5345235069436943, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.166293706878316, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.72batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 237.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163 / 6000, \n",
      " Train -- Loss: 0.5346907576534993, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1892422560711484, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.57batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 164 / 6000, \n",
      " Train -- Loss: 0.5342379394504495, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.164361997910584, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.97batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165 / 6000, \n",
      " Train -- Loss: 0.5348105695529005, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.166060199080147, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.74batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 166 / 6000, \n",
      " Train -- Loss: 0.533946669938608, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1839813096719296, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.96batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167 / 6000, \n",
      " Train -- Loss: 0.5342048467994598, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.180836345953913, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.71batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 168 / 6000, \n",
      " Train -- Loss: 0.5347195870432357, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1638980735949693, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.63batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 169 / 6000, \n",
      " Train -- Loss: 0.5337917508484388, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.17063320193635, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.83batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170 / 6000, \n",
      " Train -- Loss: 0.5348416358800668, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.164147560184855, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.81batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 232.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 171 / 6000, \n",
      " Train -- Loss: 0.5339829118025471, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1644853996835822, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.44batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172 / 6000, \n",
      " Train -- Loss: 0.5339423317412146, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.182414887821444, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 66.16batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 236.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173 / 6000, \n",
      " Train -- Loss: 0.5341332628048819, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1618676061889524, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.57batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 174 / 6000, \n",
      " Train -- Loss: 0.5341656273936364, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.166545988637276, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.84batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175 / 6000, \n",
      " Train -- Loss: 0.5341253602784245, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.1738394188730914, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.50batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 235.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 176 / 6000, \n",
      " Train -- Loss: 0.5335282839198396, Coeff: 0.669677734375 \n",
      " Val   -- Loss: 2.169562932066403, Coeff: 2.677734375 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2743/2743 [00:41<00:00, 65.73batch/s]\n",
      "Valdt: 100%|██████████| 2742/2742 [00:11<00:00, 233.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Early Stopping is reached! +++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 6000\n",
    "best = 1e6\n",
    "PATH = f\"./best_model_{dt_name}.pt\"\n",
    "\n",
    "early_stopper = EarlyStopper(patience=50, path=PATH)\n",
    "                             \n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    Loss_train = 0 \n",
    "    Loss_val = 0\n",
    "    coeff_train = 0\n",
    "    coeff_val = 0\n",
    "    with tqdm(train_loader, unit=\"batch\") as trainer:\n",
    "        for batch in trainer:\n",
    "            trainer.set_description(\"Train\")\n",
    "            train_feat = batch[:, 0:-1].to(device)\n",
    "            train_labs = batch[:, -1].to(device)\n",
    "            train_pred = model(train_feat).squeeze()\n",
    "            train_loss = torch.nn.functional.mse_loss(train_pred, train_labs)\n",
    "            train_coef = coeff_determination(train_labs, train_labs) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            Loss_train += train_loss.item()\n",
    "            coeff_train += train_coef\n",
    "\n",
    "        Loss_train /= batch_sz_trn\n",
    "        coeff_train /= batch_sz_trn\n",
    "\n",
    "    model.eval()\n",
    "    with tqdm(val_loader, unit=\"batch\") as validator:\n",
    "        for batch in validator:\n",
    "            validator.set_description(\"Valdt\")\n",
    "            val_feat = batch[:, 0:-1].to(device)\n",
    "            val_labs = batch[:, -1].to(device)\n",
    "            val_pred = model(val_feat).squeeze()\n",
    "            val_loss = torch.nn.functional.mse_loss(val_pred, val_labs)\n",
    "            val_coef = coeff_determination(val_labs, val_labs) \n",
    "\n",
    "            Loss_val += val_loss.item()\n",
    "            coeff_val += val_coef\n",
    "\n",
    "        Loss_val /= batch_sz_val\n",
    "        coeff_val /= batch_sz_val\n",
    "    \n",
    "    if early_stopper.early_stop(model.state_dict(), Loss_val):             \n",
    "        break\n",
    "        \n",
    "    print(f\"Epoch: {epoch} / {epochs}, \\n Train -- Loss: {Loss_train}, Coeff: {coeff_train} \\n Val   -- Loss: {Loss_val}, Coeff: {coeff_val} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9e410f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0041, -0.0041, -0.0017,  ..., -0.1439, -0.0051, -0.1432],\n",
       "        [ 0.0048,  0.0032, -0.0002,  ..., -0.1439, -0.0051, -0.1432],\n",
       "        [ 0.0160,  0.0027,  0.0064,  ..., -0.1439, -0.0051, -0.1432],\n",
       "        ...,\n",
       "        [ 0.0867,  0.0666,  0.1691,  ..., -0.1357,  0.0510, -0.1148],\n",
       "        [ 0.0008, -0.0119, -0.0061,  ..., -0.1439, -0.0051, -0.1431],\n",
       "        [-0.0032,  0.0075,  0.0093,  ..., -0.1439, -0.0051, -0.1431]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "next(data_iter)[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0391c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.trace(model, next(data_iter)[:,0:-1].to(device))\n",
    "traced_script_module.save(f\"traced_model_{dt_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5414719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPModel(\n",
       "  (block): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=60, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=60, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = f\"./best_model_{dt_name}.pt\"\n",
    "model = MLPModel(input_size=input_size, \n",
    "                 output_size=output_size, \n",
    "                 hidden_layers=hidden_layers, \n",
    "                 neurons_per_layer=neurons_per_layer)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "#model.to(device)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80604c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3509907, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(torch.from_numpy(test[:,:-1]))\n",
    "pred.detach().numpy().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "291d4dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00764506],\n",
       "       [ 0.02690536],\n",
       "       [ 0.011069  ],\n",
       "       ...,\n",
       "       [ 0.00414676],\n",
       "       [ 0.00921118],\n",
       "       [-0.01399088]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.detach().numpy() * scale.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ebcfa2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test[:,-1], pred.detach().numpy(), edgecolor='white', color='red')\n",
    "plt.plot([0, 0], [-100, 100], '--', color='#929591')\n",
    "plt.plot([-100, 100], [0, 0], '--', color='#929591')\n",
    "plt.xlim([-100, 100])\n",
    "plt.ylim([-100, 100])\n",
    "plt.xlabel(r'$C_s$')\n",
    "plt.ylabel(r'$\\tilde{C_s}$')\n",
    "plt.savefig(f'../nnTraining/Results/{dt_name}_correlation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae9a5ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test[:,-1], bins=10000, density=True, alpha=0.6, histtype=u'step', color='blue')\n",
    "plt.hist(pred.detach().numpy(), bins=10000, density=True, alpha=0.6, histtype=u'step', color='red')\n",
    "plt.xlim([-0.75, 0.75])\n",
    "plt.xlabel(r'$C_s$')\n",
    "plt.legend(['Ground Truth', 'MLP'])\n",
    "plt.savefig(f'../nnTraining/Results/{dt_name}_density.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0872c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
